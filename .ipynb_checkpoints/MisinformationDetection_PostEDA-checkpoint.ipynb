{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "89038a11",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Cell 1: Import additional required libraries\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.feature_extraction.text import TfidataVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import joblib\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8e3bf79a-d1a8-4b0f-b295-18bda1f89430",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_text</th>\n",
       "      <th>likes</th>\n",
       "      <th>shares</th>\n",
       "      <th>comments</th>\n",
       "      <th>sentiment_score</th>\n",
       "      <th>contains_link</th>\n",
       "      <th>contains_hashtag</th>\n",
       "      <th>platform_encoded</th>\n",
       "      <th>device_encoded</th>\n",
       "      <th>verified_encoded</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>small citizen class morning</td>\n",
       "      <td>79</td>\n",
       "      <td>62</td>\n",
       "      <td>27</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>others kind company likely improve notice meet...</td>\n",
       "      <td>78</td>\n",
       "      <td>27</td>\n",
       "      <td>31</td>\n",
       "      <td>-0.28</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>check real leader bad school name care several...</td>\n",
       "      <td>57</td>\n",
       "      <td>111</td>\n",
       "      <td>99</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>car financial security stock ball organization...</td>\n",
       "      <td>48</td>\n",
       "      <td>78</td>\n",
       "      <td>22</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>could yourself plan base rise would i question...</td>\n",
       "      <td>83</td>\n",
       "      <td>129</td>\n",
       "      <td>2</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          clean_text  likes  shares  comments  \\\n",
       "0                        small citizen class morning     79      62        27   \n",
       "1  others kind company likely improve notice meet...     78      27        31   \n",
       "2  check real leader bad school name care several...     57     111        99   \n",
       "3  car financial security stock ball organization...     48      78        22   \n",
       "4  could yourself plan base rise would i question...     83     129         2   \n",
       "\n",
       "   sentiment_score  contains_link  contains_hashtag  platform_encoded  \\\n",
       "0             0.04              0                 0                 2   \n",
       "1            -0.28              0                 0                 0   \n",
       "2             0.27              0                 0                 3   \n",
       "3             0.06              0                 0                 3   \n",
       "4             0.02              0                 0                 0   \n",
       "\n",
       "   device_encoded  verified_encoded  target  \n",
       "0               1                 1       0  \n",
       "1               0                 0       1  \n",
       "2               1                 0       0  \n",
       "3               1                 0       0  \n",
       "4               0                 0       1  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"cleaned_misinformation_dataset.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "20df9394",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Cell 2: Text cleaning function\n",
    "stop_words = set(stopwords.words('english'))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def clean_text(text):\n",
    "    text = str(text).lower()\n",
    "    text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text)\n",
    "    text = re.sub(r'[^A-Za-z\\s]', '', text)\n",
    "    text = ' '.join([lemmatizer.lemmatize(word) for word in text.split() if word not in stop_words])\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "49e1f9b2",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'text_content'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\core\\indexes\\base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'text_content'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Cell 3: Apply text preprocessing to the content column\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcleaned_text\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtext_content\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mapply(clean_text)\n\u001b[0;32m      3\u001b[0m df[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext_content\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcleaned_text\u001b[39m\u001b[38;5;124m'\u001b[39m]]\u001b[38;5;241m.\u001b[39mhead()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\core\\frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[0;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[0;32m   3810\u001b[0m     ):\n\u001b[0;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[1;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'text_content'"
     ]
    }
   ],
   "source": [
    "\n",
    "# Cell 3: Apply text preprocessing to the content column\n",
    "data['cleaned_text'] = data['text_content'].apply(clean_text)\n",
    "data[['text_content', 'cleaned_text']].head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b6d4778",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Cell 4: Encode the target label\n",
    "label_encoder = LabelEncoder()\n",
    "data['label_encoded'] = label_encoder.fit_transform(data['label'])  # Adjust if your label column has a different name\n",
    "data['label_encoded'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "731e542b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Cell 5: Split dataset\n",
    "X = data['cleaned_text']\n",
    "y = data['label_encoded']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "852c8d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Cell 6: TF-Idata Vectorization\n",
    "tfidata = TfidataVectorizer(max_features=10000, ngram_range=(1,2))\n",
    "X_train_tfidata = tfidata.fit_transform(X_train)\n",
    "X_test_tfidata = tfidata.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae9587b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Cell 7: Train Logistic Regression\n",
    "lr_model = LogisticRegression(max_iter=1000)\n",
    "lr_model.fit(X_train_tfidata, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8b96dd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Cell 8: Evaluate model\n",
    "y_pred = lr_model.predict(X_test_tfidata)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5e82340",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Cell 9: Save TF-Idata and model\n",
    "joblib.dump(tfidata, 'tfidata_vectorizer.pkl')\n",
    "joblib.dump(lr_model, 'logistic_model.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14c12513",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Cell 10: Setup transformers and tokenizer for BERT model\n",
    "from transformers import DistilBertTokenizer, TFDistilBertForSequenceClassification\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
    "from tensorflow.keras.metrics import SparseCategoricalAccuracy\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import tensorflow as tf\n",
    "\n",
    "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e123590",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Cell 11: Tokenize text for BERT\n",
    "train_encodings = tokenizer(list(X_train), truncation=True, padding=True, max_length=128)\n",
    "test_encodings = tokenizer(list(X_test), truncation=True, padding=True, max_length=128)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4efe3b90",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Cell 12: Convert encodings to TensorFlow dataset\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((dict(train_encodings), y_train)).batch(16)\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((dict(test_encodings), y_test)).batch(16)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30a1f143",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Cell 13: Train DistilBERT model\n",
    "bert_model = TFDistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased', num_labels=2)\n",
    "bert_model.compile(optimizer=Adam(learning_rate=5e-5),\n",
    "                   loss=SparseCategoricalCrossentropy(from_logits=True),\n",
    "                   metrics=[SparseCategoricalAccuracy()])\n",
    "\n",
    "bert_model.fit(train_dataset, validation_data=test_dataset, epochs=3, callbacks=[EarlyStopping(patience=1)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aa59040",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Cell 14: Evaluate BERT model\n",
    "bert_model.evaluate(test_dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56a66215",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Cell 15: Save BERT model\n",
    "bert_model.save_pretrained('bert_misinfo_model')\n",
    "tokenizer.save_pretrained('bert_misinfo_model')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e93a9646",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Cell 16: Function to make predictions using BERT\n",
    "def predict_misinfo(text):\n",
    "    inputs = tokenizer(text, return_tensors=\"tf\", truncation=True, padding=True)\n",
    "    logits = bert_model(inputs)[0]\n",
    "    prediction = tf.argmax(logits, axis=1).numpy()[0]\n",
    "    return label_encoder.inverse_transform([prediction])[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3008bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Cell 17: Test prediction\n",
    "sample_text = \"Breaking news: COVID-19 cures found in herbs!\"\n",
    "print(\"Prediction:\", predict_misinfo(sample_text))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39643923",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Cell 18: SHAP Explainability (Logistic Regression only)\n",
    "import shap\n",
    "explainer = shap.LinearExplainer(lr_model, X_train_tfidata, feature_dependence=\"independent\")\n",
    "shap_values = explainer.shap_values(X_test_tfidata[:10])\n",
    "shap.summary_plot(shap_values, X_test_tfidata[:10], feature_names=tfidata.get_feature_names_out())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e19b6498",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Cell 19: Example Flask API structure (pseudo-code)\n",
    "# from flask import Flask, request, jsonify\n",
    "# app = Flask(__name__)\n",
    "# @app.route('/predict', methods=['POST'])\n",
    "# def predict():\n",
    "#     text = request.json['text']\n",
    "#     result = predict_misinfo(text)\n",
    "#     return jsonify({'prediction': result})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2431eb3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Cell 20: Conclusion\n",
    "print(\"Logistic Regression and DistilBERT models trained. Logistic model and TF-Idata vectorizer saved.\")\n",
    "print(\"DistilBERT saved to 'bert_misinfo_model' directory. Ready for API deployment.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
